{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnames=['dtype'])\n",
    "def jax_count(spike_times, bin_edges, dtype=jnp.uint32):\n",
    "    num_bins = bin_edges.size - 1\n",
    "    idx = jnp.searchsorted(bin_edges, spike_times, side=\"right\") - 1\n",
    "    counts = jnp.bincount(idx, length=num_bins)\n",
    "\n",
    "    return jax.lax.convert_element_type(counts, dtype)\n",
    "\n",
    "def nwb_spike_count(file, interval, window, batchsize=None, dtype=jnp.uint32, save=False):\n",
    "    T = interval[1] - interval[0]\n",
    "    N = int(T // window)\n",
    "    if save:\n",
    "        readmode = \"a\"\n",
    "    else:\n",
    "        readmode = \"r\"\n",
    "    with h5py.File(file, readmode) as data:\n",
    "        spike_times = data['units']['spike_times'][:] # * [:] Loads the entire file at once\n",
    "        units = len(data['units']['id'])\n",
    "        indices = data['units']['spike_times_index']\n",
    "\n",
    "        bin_edges = jnp.linspace(interval[0]-window, interval[1], N + 2) # Add an extra bin to count less-than spikes\n",
    "\n",
    "        bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "        def indices2idxs(i):\n",
    "            minidx = indices[i]\n",
    "            maxidx = indices[i+1] if i < units - 1 else len(spike_times)\n",
    "            return range(minidx, maxidx)\n",
    "\n",
    "        if batchsize is not None:\n",
    "            nbatches = np.ceil(units / batchsize)\n",
    "        else:\n",
    "            nbatches = 1\n",
    "\n",
    "        batchis = np.arange(units)\n",
    "        # numspikes = [indices[i+1] - indices[i] for i in range(units)-1]\n",
    "        # numspikes.append(len(spike_times) - indices[-1])\n",
    "        # batchis = np.argsort(numspikes)\n",
    "        # batchis = np.argsort([len(spike_times[indices2idxs(i)]) for i in batchis])\n",
    "        batchis = np.array_split(batchis, nbatches)\n",
    "\n",
    "        @jax.jit\n",
    "        def _count(spike_times):\n",
    "            return jax_count(spike_times, bin_edges, dtype)\n",
    "\n",
    "        def count(batchi):\n",
    "            # * Get spike times for a batch\n",
    "            batch = [spike_times[indices2idxs(i)] for i in batchi]\n",
    "\n",
    "            # * Pad the batch with NaN's for JaX\n",
    "            maxlen = max([len(b) for b in batch])\n",
    "            batch = [jnp.pad(b, (0, maxlen - len(b)), constant_values=np.nan) for b in batch]\n",
    "            batch = jnp.stack(batch)\n",
    "\n",
    "            counts = jax.vmap(_count)(batch)\n",
    "            return counts\n",
    "\n",
    "        if save:\n",
    "            if 'counts' in data:\n",
    "                del data['counts']\n",
    "            if 'bin_centers' in data:\n",
    "                del data['bin_centers']\n",
    "            data.create_dataset(\"counts\", data=np.zeros((units, N), dtype=dtype))\n",
    "            for batchi in tqdm(batchis):\n",
    "                counts_batch = count(batchi)\n",
    "                data[\"counts\"][batchi, :] = counts_batch[:, 1:]\n",
    "            data.create_dataset(\"bin_centers\", data=np.array(bin_centers[1:]))\n",
    "            return file\n",
    "        else:\n",
    "            counts = [count(batchi) for batchi in tqdm(batchis)]\n",
    "            X = jnp.concatenate(counts, axis=0)\n",
    "            return X[:, 1:], bin_centers[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_counts, ts = nwb_spike_count(\"test.nwb\", (0, 9600), 0.005, batchsize=500, dtype=jnp.uint8, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 13.4483 s\n",
      "File: /var/tmp/pbs.20495.headnode/ipykernel_2792436/2454981060.py\n",
      "Function: nwb_spike_count at line 17\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    17                                           def nwb_spike_count(file, interval, window, batchsize=None, dtype=jnp.uint32, save=False):\n",
      "    18         1        880.0    880.0      0.0      T = interval[1] - interval[0]\n",
      "    19         1       2248.0   2248.0      0.0      N = int(T // window)\n",
      "    20         1        370.0    370.0      0.0      if save:\n",
      "    21                                                   readmode = \"a\"\n",
      "    22                                               else:\n",
      "    23         1        163.0    163.0      0.0          readmode = \"r\"\n",
      "    24         2  115819365.0    6e+07      0.9      with h5py.File(file, readmode) as data:\n",
      "    25         1 7812308779.0    8e+09     58.1          spike_times = data['units']['spike_times'][:] # * [:] Loads the entire file at once\n",
      "    26         1    2896197.0    3e+06      0.0          units = len(data['units']['id'])\n",
      "    27         1     102328.0 102328.0      0.0          indices = data['units']['spike_times_index']\n",
      "    28                                           \n",
      "    29         1     412297.0 412297.0      0.0          bin_edges = jnp.linspace(interval[0]-window, interval[1], N + 2) # Add an extra bin to count less-than spikes\n",
      "    30                                           \n",
      "    31         1     891018.0 891018.0      0.0          bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
      "    32                                           \n",
      "    33         1       1322.0   1322.0      0.0          def indices2idxs(i):\n",
      "    34                                                       minidx = indices[i]\n",
      "    35                                                       maxidx = indices[i+1] if i < units - 1 else len(spike_times)\n",
      "    36                                                       return range(minidx, maxidx)\n",
      "    37                                           \n",
      "    38         1        385.0    385.0      0.0          if batchsize is not None:\n",
      "    39                                                       nbatches = np.ceil(units / batchsize)\n",
      "    40                                                   else:\n",
      "    41         1        198.0    198.0      0.0              nbatches = 1\n",
      "    42                                           \n",
      "    43         1      26114.0  26114.0      0.0          batchis = np.arange(units)\n",
      "    44                                                   # numspikes = [indices[i+1] - indices[i] for i in range(units)-1]\n",
      "    45                                                   # numspikes.append(len(spike_times) - indices[-1])\n",
      "    46                                                   # batchis = np.argsort(numspikes)\n",
      "    47                                                   # batchis = np.argsort([len(spike_times[indices2idxs(i)]) for i in batchis])\n",
      "    48         1      59923.0  59923.0      0.0          batchis = np.array_split(batchis, nbatches)\n",
      "    49                                           \n",
      "    50         2     392999.0 196499.5      0.0          @jax.jit\n",
      "    51         2       1364.0    682.0      0.0          def _count(spike_times):\n",
      "    52                                                       return jax_count(spike_times, bin_edges, dtype)\n",
      "    53                                           \n",
      "    54         1        717.0    717.0      0.0          def count(batchi):\n",
      "    55                                                       # * Get spike times for a batch\n",
      "    56                                                       batch = [spike_times[indices2idxs(i)] for i in batchi]\n",
      "    57                                           \n",
      "    58                                                       # * Pad the batch with NaN's for JaX\n",
      "    59                                                       maxlen = max([len(b) for b in batch])\n",
      "    60                                                       batch = [jnp.pad(b, (0, maxlen - len(b)), constant_values=np.nan) for b in batch]\n",
      "    61                                                       batch = jnp.stack(batch)\n",
      "    62                                           \n",
      "    63                                                       counts = jax.vmap(_count)(batch)\n",
      "    64                                                       return counts\n",
      "    65                                           \n",
      "    66         1        544.0    544.0      0.0          if save:\n",
      "    67                                                       if 'counts' in data:\n",
      "    68                                                           del data['counts']\n",
      "    69                                                       if 'bin_centers' in data:\n",
      "    70                                                           del data['bin_centers']\n",
      "    71                                                       data.create_dataset(\"counts\", data=np.zeros((units, N), dtype=dtype))\n",
      "    72                                                       for batchi in tqdm(batchis):\n",
      "    73                                                           counts_batch = count(batchi)\n",
      "    74                                                           data[\"counts\"][batchi, :] = counts_batch[:, 1:]\n",
      "    75                                                       data.create_dataset(\"bin_centers\", data=np.array(bin_centers[1:]))\n",
      "    76                                                       return file\n",
      "    77                                                   else:\n",
      "    78         2 5514485706.0    3e+09     41.0              counts = [count(batchi) for batchi in tqdm(batchis)]\n",
      "    79         1      55881.0  55881.0      0.0              X = jnp.concatenate(counts, axis=0)\n",
      "    80         1     859898.0 859898.0      0.0              return X[:, 1:], bin_centers[1:]"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f nwb_spike_count nwb_spike_count(\"test.nwb\", (0, 9600), 0.005, batchsize=100, dtype=jnp.uint8, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
